{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618bb1e0",
   "metadata": {},
   "source": [
    "# Indeed.com daily job scraping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b9238",
   "metadata": {},
   "source": [
    "### Set up driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3447587",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = '/home/nessa/Downloads/chromedriver'\n",
    "driver      = webdriver.Chrome(executable_path = DRIVER_PATH)\n",
    "driver.minimize_window()\n",
    "wait=WebDriverWait(driver, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit wait time\n",
    "waittime=60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d50c5",
   "metadata": {},
   "source": [
    "### What are we searching for and where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_key_words = ['data science', 'machine learning', 'quantitative researcher']\n",
    "loc_key_words = ['Seattle', 'Portland', 'San Francisco', 'Oakland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub select by \n",
    "ids=['filter-jobtype','filter-radius','filter-dateposted']\n",
    "options=[\"Full-time\",\"within 10 miles\",\"Last 24 hours\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a477b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def selections(id_,option):\n",
    "    \"\"\"\n",
    "    function that executes a filter selection\n",
    "    id_ : id of filter element\n",
    "    option: name (string) specifying criterion \n",
    "    \"\"\"\n",
    "    print('{}: {}'.format(id_, option))\n",
    "\n",
    "    drop = WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.ID, id_)))\n",
    "    time.sleep(1)\n",
    "    drop.click()\n",
    "\n",
    "    XPATH = '//a[contains(text(),\"{}\")]'.format(option)\n",
    "    drop = WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.XPATH, XPATH)))\n",
    "    time.sleep(1)\n",
    "    drop.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "titles=[]\n",
    "companies=[]\n",
    "locations=[]\n",
    "cities=[]\n",
    "descriptions=[]\n",
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "\n",
    "def fill_entries():\n",
    "    \"\"\"\n",
    "    just a wrapper for scraping info for every job in a search\n",
    "    yeah, technically we should probably pass the lists above...\n",
    "    \"\"\"\n",
    "    \n",
    "    driver.implicitly_wait(3) \n",
    "\n",
    "    job_cards = driver.find_elements_by_xpath('//div[contains(@class,\"job_seen_beacon\")]')\n",
    "    print('{} jobs found'.format(len(job_cards)))\n",
    "    for job in job_cards:\n",
    " \n",
    "        driver.execute_script(\"window.scrollTo(0, 100)\") \n",
    "        job.click()\n",
    "        title = driver.find_elements_by_xpath('//div[contains(@class,\"jobsearch-JobInfoHeader-title\")]')[0].text\n",
    "        titles.append(re.split('\\n', title)[0])\n",
    "\n",
    "        info_list = driver.find_elements_by_xpath('//div[contains(@class,\"jobsearch-CompanyInfoWithoutHeaderImage\")]')\n",
    "        text=info_list[0].text\n",
    "        split_text = re.split('\\n', text)\n",
    "        company = split_text[0]\n",
    "        loc     = split_text[-1]\n",
    "        try:\n",
    "            city, loc = re.split('â€¢',loc)\n",
    "        except:\n",
    "            city = loc\n",
    "            loc  ='onsite' \n",
    "\n",
    "        # get salary information from job ad; if not available, use indeed's estimate; for no info, make it a 'nan'\n",
    "        text = job.find_element_by_xpath('//*[@id=\"jobDetailsSection\"]').text\n",
    "        if ('salary' in text) or ('Salary' in text):\n",
    "            salary = re.split('\\n',text)[2]\n",
    "        else:\n",
    "            try:\n",
    "                salary=driver.find_element_by_xpath('//*[contains(text(),\"{}\")]'.format(\"Indeed's estimated salary\")).text\n",
    "\n",
    "            except:\n",
    "                salary='nan'\n",
    "        #do some regular expression stuff to get them all into the same format\n",
    "        try:\n",
    "            min_salary, max_salary=re.split(' - ', salary)\n",
    "            max_salary=re.split(' ', max_salary)[0]\n",
    "            min_salary=re.sub('K', ',000', min_salary)\n",
    "            max_salary=re.sub('K', ',000', min_salary)\n",
    "        except:\n",
    "            min_salary, max_salary = salary, salary\n",
    "\n",
    "        min_salaries.append(min_salary)\n",
    "        max_salaries.append(max_salary)\n",
    "\n",
    "\n",
    "\n",
    "        locations.append(loc)\n",
    "        cities.append(city)\n",
    "\n",
    "        companies.append(company)\n",
    "        \n",
    "        text = job.find_element_by_xpath('//*[@id=\"jobDescriptionText\"]').text\n",
    "        descriptions.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50647a0f",
   "metadata": {},
   "source": [
    "### Run the job search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ab8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for job_key_word in job_key_words:\n",
    "    for loc_key_word in loc_key_words:\n",
    "        print('searching for {} in {}...'.format(job_key_word,loc_key_word))\n",
    "        \n",
    "        driver.get('https://indeed.com')\n",
    "        search_job = WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.ID, \"text-input-what\")))\n",
    "        time.sleep(1)\n",
    "        search_job.send_keys([job_key_word])\n",
    "        search_job.send_keys(Keys.ENTER)\n",
    "\n",
    "        WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.ID,\"text-input-where\")))\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_id(\"text-input-where\").click()\n",
    "        driver.find_element_by_id(\"text-input-where\").send_keys(Keys.CONTROL + \"a\")\n",
    "        driver.find_element_by_id(\"text-input-where\").send_keys(Keys.DELETE)\n",
    "\n",
    "        search_loc = WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.ID,\"text-input-where\")))\n",
    "        time.sleep(1)\n",
    "        search_loc.send_keys(Keys.CONTROL + \"a\")\n",
    "        search_loc.send_keys(Keys.DELETE)\n",
    "        search_loc.send_keys([loc_key_word])\n",
    "        search_loc.send_keys(Keys.ENTER)\n",
    "        search =WebDriverWait(driver, waittime).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"jobsearch\"]/button')))\n",
    "        time.sleep(1)\n",
    "        search.click()\n",
    "        \n",
    "        print('selecting ...')\n",
    "        for id_, option in zip(ids,options):\n",
    "            selections(id_,option)\n",
    "        fill_entries()\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ab284",
   "metadata": {},
   "source": [
    "### Put results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_da=pd.DataFrame()\n",
    "df_da['Title']=titles\n",
    "df_da['Company']=companies\n",
    "df_da['City']=cities\n",
    "df_da['Location']=locations\n",
    "df_da['Description']=descriptions\n",
    "df_da['Minimum_salary']=min_salaries\n",
    "df_da['Maximum_salary']=max_salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672856",
   "metadata": {},
   "source": [
    "### Add some more constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_pairs = [['Title','Engineer'], ['Title','Product'], ['Company', 'Amazon'], ['Title','Postdoc'],\n",
    "              ['Company', 'Tesla'], ['Company', 'Meta'], ['Title','NLP'], ['Company','University']]\n",
    "\n",
    "df_da['selections'] = np.zeros(len(df_da)).astype(bool)\n",
    "\n",
    "for drop_pair in drop_pairs:\n",
    "    new_selec = df_da[drop_pair[0]].apply(lambda x: True if drop_pair[1] in x else False)\n",
    "    df_da['selections']=new_selec|df_da['selections']\n",
    "df_da = df_da[~df_da['selections']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749e1f",
   "metadata": {},
   "source": [
    "### Do some processing we forgot to do earlier and add salary constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_da.Minimum_salary = df_da.Minimum_salary.apply(lambda x: re.findall(r'\\d+', x)[0] if len(re.findall(r'\\d+', x))>0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd39d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_da.Maximum_salary = df_da.Maximum_salary.apply(lambda x: re.findall(r'\\d+', x)[0] if len(re.findall(r'\\d+', x))>0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(x):\n",
    "    try:\n",
    "        result = np.isnan(x)\n",
    "    except:\n",
    "        result = int(x)>140\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10968c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_cap = df_da.Maximum_salary.apply(lambda x: count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf549b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_da[salary_cap]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a067d82",
   "metadata": {},
   "source": [
    "### Print descriptions for remaining job ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, company, text in zip(df_da[salary_cap].Title, df_da[salary_cap].Company, df_da[salary_cap].Description):\n",
    "    print('-----------------------')\n",
    "    print(title,', ', company)\n",
    "    print('\\n')\n",
    "    print(text)\n",
    "    print('-----------------------')\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58067e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
